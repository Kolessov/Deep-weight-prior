{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FADA.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMJz1A57WVVrZmNJ4aXP0Xd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kolessov/Deep-weight-prior/blob/main/FADA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xe6X7FkxLjWV"
      },
      "source": [
        "import torch\n",
        "import time\n",
        "import numpy as np\n",
        "import argparse\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MN_4CWjQLpoO"
      },
      "source": [
        "class BasicModule(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(BasicModule,self).__init__()\n",
        "\n",
        "    def load(self,path):\n",
        "        self.load_state_dict(torch.load(path))\n",
        "\n",
        "    def save(self, path=None):\n",
        "        if path is None:\n",
        "            name='result/best_model.pth'\n",
        "            torch.save(self.state_dict(),name)\n",
        "            return name\n",
        "        else:\n",
        "            torch.save(self.state_dict(),path)\n",
        "            return path"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TRUmsbjgMIAS"
      },
      "source": [
        "class DCD(BasicModule):\n",
        "    def __init__(self,h_features=64,input_features=2*84):\n",
        "        super(DCD,self).__init__()\n",
        "\n",
        "        self.fc1=nn.Linear(input_features,h_features)\n",
        "        self.fc2=nn.Linear(h_features,h_features)\n",
        "        self.fc3=nn.Linear(h_features,4)\n",
        "\n",
        "    def forward(self,inputs):\n",
        "        out=F.relu(self.fc1(inputs))\n",
        "        out=self.fc2(out)\n",
        "        return F.softmax(self.fc3(out),dim=1)\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TlM31aY_N8H4"
      },
      "source": [
        "class Classifier(BasicModule):\n",
        "    def __init__(self,input_features=84):\n",
        "        super(Classifier,self).__init__()\n",
        "        self.fc=nn.Linear(input_features,10)\n",
        "\n",
        "    def forward(self,input):\n",
        "        return F.softmax(self.fc(input),dim=1)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ajRCIkmN9N-"
      },
      "source": [
        "class Encoder(BasicModule):\n",
        "    def __init__(self):\n",
        "        super(Encoder,self).__init__()\n",
        "\n",
        "        self.conv1=nn.Conv2d(1,6,5)\n",
        "        self.conv2=nn.Conv2d(6,16,5)\n",
        "        self.fc1=nn.Linear(256,120)\n",
        "        self.fc2=nn.Linear(120,84)\n",
        "        #self.fc3=nn.Linear(84,64)\n",
        "\n",
        "    def forward(self,input):\n",
        "        out=F.relu(self.conv1(input))\n",
        "        out=F.max_pool2d(out,2)\n",
        "        out=F.relu(self.conv2(out))\n",
        "        out=F.max_pool2d(out,2)\n",
        "        out=out.view(out.size(0),-1)\n",
        "\n",
        "        out=F.relu(self.fc1(out))\n",
        "        #out=F.relu(self.fc2(out))\n",
        "        out=self.fc2(out)\n",
        "\n",
        "        return out\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nubHjCcGQrxn"
      },
      "source": [
        "def usps_dataloader(batch_size=256,train=True):\n",
        "\n",
        "    dataloader=DataLoader(\n",
        "    datasets.USPS('./data',train=train,download=True,\n",
        "                   transform=transforms.Compose([ \n",
        "                       transforms.ToTensor(),\n",
        "                       transforms.Resize((28,28)),\n",
        "                       transforms.Normalize((0.5,),(0.5,))\n",
        "                   ])),\n",
        "    batch_size=batch_size,shuffle=True)\n",
        "\n",
        "    return dataloader"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gCJdqn8oTUsN"
      },
      "source": [
        "def svhn_dataloader(batch_size=4,train=True):\n",
        "    dataloader = DataLoader(\n",
        "        datasets.SVHN('./data', split=('train' if train else 'test'), download=True,\n",
        "                       transform=transforms.Compose([\n",
        "                           transforms.Resize((28,28)),\n",
        "                           transforms.Grayscale(),\n",
        "                           transforms.ToTensor(),\n",
        "                           transforms.Normalize((0.5,), (0.5,))\n",
        "                       ])),\n",
        "        batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    return dataloader"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_9UdBG6_tZKf",
        "outputId": "f96c13f3-df3e-4f12-8397-39fdfe2b6c95"
      },
      "source": [
        "!wget www.di.ens.fr/~lelarge/MNIST.tar.gz\n",
        "!tar -zxvf MNIST.tar.gz\n",
        "\n",
        "dt = datasets.MNIST('./',train=True,download=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-03-29 16:56:28--  http://www.di.ens.fr/~lelarge/MNIST.tar.gz\n",
            "Resolving www.di.ens.fr (www.di.ens.fr)... 129.199.99.14\n",
            "Connecting to www.di.ens.fr (www.di.ens.fr)|129.199.99.14|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://www.di.ens.fr/~lelarge/MNIST.tar.gz [following]\n",
            "--2021-03-29 16:56:29--  https://www.di.ens.fr/~lelarge/MNIST.tar.gz\n",
            "Connecting to www.di.ens.fr (www.di.ens.fr)|129.199.99.14|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [application/x-gzip]\n",
            "Saving to: ‘MNIST.tar.gz’\n",
            "\n",
            "MNIST.tar.gz            [       <=>          ]  33.20M  5.03MB/s    in 19s     \n",
            "\n",
            "2021-03-29 16:56:49 (1.77 MB/s) - ‘MNIST.tar.gz’ saved [34813078]\n",
            "\n",
            "MNIST/\n",
            "MNIST/raw/\n",
            "MNIST/raw/train-labels-idx1-ubyte\n",
            "MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
            "MNIST/raw/t10k-labels-idx1-ubyte\n",
            "MNIST/raw/t10k-images-idx3-ubyte.gz\n",
            "MNIST/raw/train-images-idx3-ubyte\n",
            "MNIST/raw/train-labels-idx1-ubyte.gz\n",
            "MNIST/raw/t10k-images-idx3-ubyte\n",
            "MNIST/raw/train-images-idx3-ubyte.gz\n",
            "MNIST/processed/\n",
            "MNIST/processed/training.pt\n",
            "MNIST/processed/test.pt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c__0i6JSVJC3"
      },
      "source": [
        "def sample_data():\n",
        "    dataset=datasets.USPS('./data',train=True,download=True,\n",
        "                   transform=transforms.Compose([\n",
        "                       transforms.ToTensor(),\n",
        "                       transforms.Resize((28,28)),\n",
        "                       transforms.Normalize((0.5, ),(0.5, ))\n",
        "                   ]))\n",
        "    n=len(dataset)\n",
        "\n",
        "    X=torch.Tensor(n,1,28,28)\n",
        "    Y=torch.LongTensor(n)\n",
        "\n",
        "    inds=torch.randperm(len(dataset))\n",
        "    for i,index in enumerate(inds):\n",
        "        x,y=dataset[index]\n",
        "        X[i]=x\n",
        "        Y[i]=y\n",
        "    return X,Y\n",
        "\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K6hABSQ5WSQu"
      },
      "source": [
        "def create_target_samples( mask_matrix):\n",
        "\n",
        "    dataset=datasets.SVHN('./data', split='train', download=True,\n",
        "                       transform=transforms.Compose([\n",
        "                           transforms.Resize((28,28)),\n",
        "                           transforms.Grayscale(),\n",
        "                           transforms.ToTensor(),\n",
        "                           transforms.Normalize((0.5, ), (0.5,))\n",
        "                       ]))\n",
        "    \n",
        "    \"\"\"\n",
        "    X,Y=[],[]\n",
        "    classes=10*[n]\n",
        "\n",
        "    i=0\n",
        "    while True:\n",
        "        if len(X)==n*10:\n",
        "            break\n",
        "        x,y=dataset[i]\n",
        "        if classes[y]>0:\n",
        "            X.append(x)\n",
        "            Y.append(y)\n",
        "            classes[y]-=1\n",
        "        i+=1\n",
        "\n",
        "    assert (len(X)==n*10)\n",
        "    \"\"\"\n",
        "\n",
        "    X,Y =[],[]\n",
        "\n",
        "    for label, num_elements in enumerate(mask_matrix):\n",
        "\n",
        "      idxs = torch.nonzero( torch.tensor( [dataset[i][1] == label for i in range(len(dataset))]  ) )\n",
        "      idxs = idxs[torch.randperm(len(idxs))]\n",
        "\n",
        "      counter = 0\n",
        "      while counter < num_elements:\n",
        "        X.append(dataset[idxs[counter]][0])\n",
        "        Y.append(dataset[idxs[counter]][1])\n",
        "        counter += 1\n",
        "      \n",
        "\n",
        "\n",
        "    return torch.stack(X,dim=0),torch.from_numpy(np.array(Y))"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dku_YyjGh0EU"
      },
      "source": [
        "#opt=vars(parser.parse_args())\n",
        "\n",
        "use_cuda=True if torch.cuda.is_available() else False\n",
        "device=torch.device('cuda:0') if use_cuda else torch.device('cpu')\n",
        "torch.manual_seed(1)\n",
        "if use_cuda:\n",
        "    torch.cuda.manual_seed(1)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QGb_bV04lHJb"
      },
      "source": [
        "X_s,Y_s= sample_data()\n",
        "#X_t,Y_t = create_target_samples()"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jLJyIlbgrZos",
        "outputId": "64fd821c-4f20-4f50-c76c-f5e204714dab"
      },
      "source": [
        "X_t,Y_t = create_target_samples([2,2,3,6,5,5,4,7,2,3])"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using downloaded and verified file: ./data/train_32x32.mat\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gu5M9e07ZCbS"
      },
      "source": [
        "def create_groups(X_s,Y_s,X_t,Y_t,mask_matrix,seed=1):\n",
        "    #change seed so every time wo get group data will different in source domain,but in target domain, data not change\n",
        "\n",
        "    torch.manual_seed(1 + seed)\n",
        "    torch.cuda.manual_seed(1 + seed)\n",
        "\n",
        "\n",
        "    n=X_t.shape[0] # 38\n",
        "\n",
        "\n",
        "    #shuffle order\n",
        "    classes = torch.unique(Y_t) # 0 1 .. 9\n",
        "    #classes=classes[torch.randperm(len(classes))] # 7 8 ..2\n",
        "\n",
        "\n",
        "    class_num=classes.shape[0] \n",
        "    #shot=n//class_num # 7\n",
        "\n",
        "\n",
        "\n",
        "    def s_idxs(c):\n",
        "        idx=torch.nonzero(Y_s.eq(int(c)))\n",
        "\n",
        "        return idx[torch.randperm(len(idx))][:7*2].squeeze() \n",
        "\n",
        "    def t_idxs(c):\n",
        "        return torch.nonzero(Y_t.eq(int(c)))[:7].squeeze()\n",
        "\n",
        "    source_idxs = list(map(s_idxs, classes))\n",
        "    target_idxs = list(map(t_idxs, classes))\n",
        "\n",
        "    source_matrix = source_idxs\n",
        "    target_matrix = target_idxs\n",
        " \n",
        "\n",
        "\n",
        "    G1, G2, G3, G4 = [], [] , [] , []\n",
        "    Y1, Y2 , Y3 , Y4 = [], [] ,[] ,[]\n",
        "\n",
        "   \n",
        "    for i in range(10):\n",
        "        for j in range(mask_matrix[i]):\n",
        "            G1.append(( X_s[source_matrix[i][j*2]], X_s[source_matrix[i][j*2+1]]))\n",
        "            Y1.append((Y_s[source_matrix[i][j*2]],Y_s[source_matrix[i][j*2+1]]))\n",
        "\n",
        "            \n",
        "            G2.append((X_s[source_matrix[i][j]],X_t[target_matrix[i][j]]))\n",
        "            Y2.append((Y_s[source_matrix[i][j]],Y_t[target_matrix[i][j]]))\n",
        "\n",
        "            G3.append((X_s[source_matrix[i%10][j]],X_s[source_matrix[(i+1)%10][j]]))\n",
        "            Y3.append((Y_s[source_matrix[i % 10][j]], Y_s[source_matrix[(i + 1) % 10][j]]))\n",
        "             \n",
        "           \n",
        "\n",
        "            G4.append((X_s[source_matrix[i%10][j]],X_t[target_matrix[(i+1)%10][0]]))\n",
        "            Y4.append((Y_s[source_matrix[i % 10][j]], Y_t[target_matrix[(i + 1) % 10][0]]))\n",
        "\n",
        " \n",
        "    groups=[G1,G2,G3,G4]\n",
        "    groups_y=[Y1,Y2,Y3,Y4]\n",
        "\n",
        "    #make sure we sampled enough samples\n",
        "    #for g in groups:\n",
        "        #assert(len(g)==n)\n",
        "    return groups,groups_y"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DBp0fNG-ZpN4"
      },
      "source": [
        "def sample_groups(X_s,Y_s,X_t,Y_t,mask_matrix,seed=1):\n",
        "\n",
        "\n",
        "    print(\"Sampling groups\")\n",
        "    return create_groups(X_s,Y_s,X_t,Y_t,mask_matrix, seed=seed)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0u9L31m8icPO"
      },
      "source": [
        "batch_size=32\n",
        "n_epochs_1 = 10\n",
        "#n_target_samples = 7\n",
        "n_epochs_2 = 100\n",
        "n_epochs_3 = 100"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ebUexeqiEQe",
        "outputId": "3221f953-db6c-4da7-960c-1b19e456a61b"
      },
      "source": [
        "train_dataloader= usps_dataloader(batch_size=batch_size,train=True)\n",
        "test_dataloader= usps_dataloader(batch_size=batch_size,train=False)\n",
        "\n",
        "classifier= Classifier()\n",
        "encoder= Encoder()\n",
        "discriminator= DCD(input_features=2*84)\n",
        "\n",
        "classifier.to(device)\n",
        "encoder.to(device)\n",
        "discriminator.to(device)\n",
        "loss_fn=torch.nn.CrossEntropyLoss()\n",
        "\n",
        "optimizer=torch.optim.Adam(list(encoder.parameters())+list(classifier.parameters()))\n",
        "\n",
        "\n",
        "for epoch in range(n_epochs_1):\n",
        "\n",
        "    for data,labels in train_dataloader:\n",
        "\n",
        "        data=data.to(device)\n",
        "        labels=labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        y_pred=classifier(encoder(data))\n",
        "\n",
        "        loss=loss_fn(y_pred,labels)\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "    acc=0\n",
        "    for data,labels in test_dataloader:\n",
        "        data=data.to(device)\n",
        "        labels=labels.to(device)\n",
        "        y_test_pred=classifier(encoder(data))\n",
        "        acc+=(torch.max(y_test_pred,1)[1]==labels).float().mean().item()\n",
        "\n",
        "    accuracy=round(acc / float(len(test_dataloader)), 3)\n",
        "\n",
        "    print(\"step1----Epoch %d/%d  accuracy: %.3f \"%(epoch+1,n_epochs_1,accuracy))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "step1----Epoch 1/10  accuracy: 0.854 \n",
            "step1----Epoch 2/10  accuracy: 0.900 \n",
            "step1----Epoch 3/10  accuracy: 0.912 \n",
            "step1----Epoch 4/10  accuracy: 0.913 \n",
            "step1----Epoch 5/10  accuracy: 0.923 \n",
            "step1----Epoch 6/10  accuracy: 0.929 \n",
            "step1----Epoch 7/10  accuracy: 0.936 \n",
            "step1----Epoch 8/10  accuracy: 0.928 \n",
            "step1----Epoch 9/10  accuracy: 0.933 \n",
            "step1----Epoch 10/10  accuracy: 0.937 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bxwiHOTa1xV_",
        "outputId": "634587e2-5413-44a7-c487-4add06418e32"
      },
      "source": [
        "groups,aa =  sample_groups(X_s,Y_s,X_t,Y_t,[2,2,3,6,5,5,4,7,2,3])"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sampling groups\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dy_frzBYAL0P"
      },
      "source": [
        "mask_matrix = [2,2,3,6,5,5,4,7,2,3]"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j2oK9EUmpNG0",
        "outputId": "1820179b-62dd-4632-f06c-497676d6fa31"
      },
      "source": [
        "optimizer_D=torch.optim.Adam(discriminator.parameters(),lr=0.001)\n",
        "\n",
        "\n",
        "for epoch in range(n_epochs_2):\n",
        "    # data\n",
        "    groups,aa =  sample_groups(X_s,Y_s,X_t,Y_t,mask_matrix,seed=epoch)\n",
        "    \n",
        "    \n",
        "\n",
        "    n_iters = 4 * len(groups[1])\n",
        "    index_list = torch.randperm(n_iters)\n",
        "    mini_batch_size=20 #use mini_batch train can be more stable\n",
        "\n",
        "\n",
        "    loss_mean=[]\n",
        "\n",
        "    X1=[]\n",
        "    X2=[]\n",
        "    ground_truths=[]\n",
        "\n",
        "    for index in range(n_iters):\n",
        "\n",
        "        ground_truth = index_list[index]//len(groups[1]) # from which subgroup\n",
        "\n",
        "        x1,x2 = groups[ground_truth][index_list[index]-len(groups[1])*ground_truth]\n",
        "        X1.append(x1)\n",
        "        X2.append(x2)\n",
        "        ground_truths.append(ground_truth)\n",
        "\n",
        "        #select data for a mini-batch to train\n",
        "        if (index+1)%mini_batch_size==0:\n",
        "\n",
        "            X1=torch.stack(X1)\n",
        "            X2=torch.stack(X2)\n",
        "            ground_truths=torch.LongTensor(ground_truths)\n",
        "            X1=X1.to(device)\n",
        "            X2=X2.to(device)\n",
        "            ground_truths=ground_truths.to(device)\n",
        "\n",
        "            optimizer_D.zero_grad()\n",
        "            X_cat=torch.cat([encoder(X1),encoder(X2)],1)\n",
        "\n",
        "\n",
        "            y_pred=discriminator(X_cat.detach())\n",
        "\n",
        "\n",
        "            loss=loss_fn(y_pred,ground_truths)\n",
        "            loss.backward()\n",
        "            optimizer_D.step()\n",
        "            loss_mean.append(loss.item())\n",
        "            X1 = []\n",
        "            X2 = []\n",
        "            ground_truths = []\n",
        "\n",
        "    print(\"step2----Epoch %d/%d loss:%.3f\"%(epoch+1,n_epochs_2,np.mean(loss_mean)))\n"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sampling groups\n",
            "step2----Epoch 1/100 loss:1.387\n",
            "Sampling groups\n",
            "step2----Epoch 2/100 loss:1.318\n",
            "Sampling groups\n",
            "step2----Epoch 3/100 loss:1.262\n",
            "Sampling groups\n",
            "step2----Epoch 4/100 loss:1.208\n",
            "Sampling groups\n",
            "step2----Epoch 5/100 loss:1.165\n",
            "Sampling groups\n",
            "step2----Epoch 6/100 loss:1.132\n",
            "Sampling groups\n",
            "step2----Epoch 7/100 loss:1.084\n",
            "Sampling groups\n",
            "step2----Epoch 8/100 loss:1.045\n",
            "Sampling groups\n",
            "step2----Epoch 9/100 loss:1.030\n",
            "Sampling groups\n",
            "step2----Epoch 10/100 loss:1.004\n",
            "Sampling groups\n",
            "step2----Epoch 11/100 loss:0.966\n",
            "Sampling groups\n",
            "step2----Epoch 12/100 loss:0.952\n",
            "Sampling groups\n",
            "step2----Epoch 13/100 loss:0.939\n",
            "Sampling groups\n",
            "step2----Epoch 14/100 loss:0.921\n",
            "Sampling groups\n",
            "step2----Epoch 15/100 loss:0.904\n",
            "Sampling groups\n",
            "step2----Epoch 16/100 loss:0.927\n",
            "Sampling groups\n",
            "step2----Epoch 17/100 loss:0.900\n",
            "Sampling groups\n",
            "step2----Epoch 18/100 loss:0.887\n",
            "Sampling groups\n",
            "step2----Epoch 19/100 loss:0.866\n",
            "Sampling groups\n",
            "step2----Epoch 20/100 loss:0.862\n",
            "Sampling groups\n",
            "step2----Epoch 21/100 loss:0.858\n",
            "Sampling groups\n",
            "step2----Epoch 22/100 loss:0.854\n",
            "Sampling groups\n",
            "step2----Epoch 23/100 loss:0.856\n",
            "Sampling groups\n",
            "step2----Epoch 24/100 loss:0.845\n",
            "Sampling groups\n",
            "step2----Epoch 25/100 loss:0.838\n",
            "Sampling groups\n",
            "step2----Epoch 26/100 loss:0.817\n",
            "Sampling groups\n",
            "step2----Epoch 27/100 loss:0.837\n",
            "Sampling groups\n",
            "step2----Epoch 28/100 loss:0.826\n",
            "Sampling groups\n",
            "step2----Epoch 29/100 loss:0.824\n",
            "Sampling groups\n",
            "step2----Epoch 30/100 loss:0.800\n",
            "Sampling groups\n",
            "step2----Epoch 31/100 loss:0.803\n",
            "Sampling groups\n",
            "step2----Epoch 32/100 loss:0.837\n",
            "Sampling groups\n",
            "step2----Epoch 33/100 loss:0.836\n",
            "Sampling groups\n",
            "step2----Epoch 34/100 loss:0.799\n",
            "Sampling groups\n",
            "step2----Epoch 35/100 loss:0.798\n",
            "Sampling groups\n",
            "step2----Epoch 36/100 loss:0.816\n",
            "Sampling groups\n",
            "step2----Epoch 37/100 loss:0.826\n",
            "Sampling groups\n",
            "step2----Epoch 38/100 loss:0.819\n",
            "Sampling groups\n",
            "step2----Epoch 39/100 loss:0.798\n",
            "Sampling groups\n",
            "step2----Epoch 40/100 loss:0.780\n",
            "Sampling groups\n",
            "step2----Epoch 41/100 loss:0.811\n",
            "Sampling groups\n",
            "step2----Epoch 42/100 loss:0.779\n",
            "Sampling groups\n",
            "step2----Epoch 43/100 loss:0.831\n",
            "Sampling groups\n",
            "step2----Epoch 44/100 loss:0.809\n",
            "Sampling groups\n",
            "step2----Epoch 45/100 loss:0.800\n",
            "Sampling groups\n",
            "step2----Epoch 46/100 loss:0.795\n",
            "Sampling groups\n",
            "step2----Epoch 47/100 loss:0.785\n",
            "Sampling groups\n",
            "step2----Epoch 48/100 loss:0.794\n",
            "Sampling groups\n",
            "step2----Epoch 49/100 loss:0.795\n",
            "Sampling groups\n",
            "step2----Epoch 50/100 loss:0.787\n",
            "Sampling groups\n",
            "step2----Epoch 51/100 loss:0.806\n",
            "Sampling groups\n",
            "step2----Epoch 52/100 loss:0.792\n",
            "Sampling groups\n",
            "step2----Epoch 53/100 loss:0.788\n",
            "Sampling groups\n",
            "step2----Epoch 54/100 loss:0.786\n",
            "Sampling groups\n",
            "step2----Epoch 55/100 loss:0.794\n",
            "Sampling groups\n",
            "step2----Epoch 56/100 loss:0.789\n",
            "Sampling groups\n",
            "step2----Epoch 57/100 loss:0.805\n",
            "Sampling groups\n",
            "step2----Epoch 58/100 loss:0.801\n",
            "Sampling groups\n",
            "step2----Epoch 59/100 loss:0.806\n",
            "Sampling groups\n",
            "step2----Epoch 60/100 loss:0.814\n",
            "Sampling groups\n",
            "step2----Epoch 61/100 loss:0.793\n",
            "Sampling groups\n",
            "step2----Epoch 62/100 loss:0.785\n",
            "Sampling groups\n",
            "step2----Epoch 63/100 loss:0.776\n",
            "Sampling groups\n",
            "step2----Epoch 64/100 loss:0.762\n",
            "Sampling groups\n",
            "step2----Epoch 65/100 loss:0.788\n",
            "Sampling groups\n",
            "step2----Epoch 66/100 loss:0.768\n",
            "Sampling groups\n",
            "step2----Epoch 67/100 loss:0.778\n",
            "Sampling groups\n",
            "step2----Epoch 68/100 loss:0.769\n",
            "Sampling groups\n",
            "step2----Epoch 69/100 loss:0.761\n",
            "Sampling groups\n",
            "step2----Epoch 70/100 loss:0.793\n",
            "Sampling groups\n",
            "step2----Epoch 71/100 loss:0.771\n",
            "Sampling groups\n",
            "step2----Epoch 72/100 loss:0.794\n",
            "Sampling groups\n",
            "step2----Epoch 73/100 loss:0.831\n",
            "Sampling groups\n",
            "step2----Epoch 74/100 loss:0.782\n",
            "Sampling groups\n",
            "step2----Epoch 75/100 loss:0.787\n",
            "Sampling groups\n",
            "step2----Epoch 76/100 loss:0.758\n",
            "Sampling groups\n",
            "step2----Epoch 77/100 loss:0.781\n",
            "Sampling groups\n",
            "step2----Epoch 78/100 loss:0.766\n",
            "Sampling groups\n",
            "step2----Epoch 79/100 loss:0.796\n",
            "Sampling groups\n",
            "step2----Epoch 80/100 loss:0.776\n",
            "Sampling groups\n",
            "step2----Epoch 81/100 loss:0.763\n",
            "Sampling groups\n",
            "step2----Epoch 82/100 loss:0.761\n",
            "Sampling groups\n",
            "step2----Epoch 83/100 loss:0.811\n",
            "Sampling groups\n",
            "step2----Epoch 84/100 loss:0.778\n",
            "Sampling groups\n",
            "step2----Epoch 85/100 loss:0.774\n",
            "Sampling groups\n",
            "step2----Epoch 86/100 loss:0.785\n",
            "Sampling groups\n",
            "step2----Epoch 87/100 loss:0.772\n",
            "Sampling groups\n",
            "step2----Epoch 88/100 loss:0.789\n",
            "Sampling groups\n",
            "step2----Epoch 89/100 loss:0.765\n",
            "Sampling groups\n",
            "step2----Epoch 90/100 loss:0.772\n",
            "Sampling groups\n",
            "step2----Epoch 91/100 loss:0.801\n",
            "Sampling groups\n",
            "step2----Epoch 92/100 loss:0.765\n",
            "Sampling groups\n",
            "step2----Epoch 93/100 loss:0.785\n",
            "Sampling groups\n",
            "step2----Epoch 94/100 loss:0.765\n",
            "Sampling groups\n",
            "step2----Epoch 95/100 loss:0.755\n",
            "Sampling groups\n",
            "step2----Epoch 96/100 loss:0.819\n",
            "Sampling groups\n",
            "step2----Epoch 97/100 loss:0.777\n",
            "Sampling groups\n",
            "step2----Epoch 98/100 loss:0.777\n",
            "Sampling groups\n",
            "step2----Epoch 99/100 loss:0.786\n",
            "Sampling groups\n",
            "step2----Epoch 100/100 loss:0.802\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bXeivJHt6bXI",
        "outputId": "85f8d95c-de8e-46a6-fd45-02153e5ad034"
      },
      "source": [
        "optimizer_g_h=torch.optim.Adam(list(encoder.parameters())+list(classifier.parameters()),lr=0.001)\n",
        "optimizer_d=torch.optim.Adam(discriminator.parameters(),lr=0.001)\n",
        "\n",
        "\n",
        "test_dataloader= svhn_dataloader(train=False,batch_size = batch_size)\n",
        "\n",
        "acc_list = []\n",
        "acc_class_list = []\n",
        "\n",
        "for epoch in range(n_epochs_3):\n",
        "    #---training g and h , DCD is frozen\n",
        "\n",
        "    groups, groups_y = sample_groups(X_s,Y_s,X_t,Y_t,mask_matrix,seed= n_epochs_2 + epoch)\n",
        "    G1, G2, G3, G4 = groups\n",
        "    Y1, Y2, Y3, Y4 = groups_y\n",
        "\n",
        "    groups_2 = [G2, G4]\n",
        "    groups_y_2 = [Y2, Y4]\n",
        "\n",
        "    n_iters = 2 * len(G2)\n",
        "    index_list = torch.randperm(n_iters)\n",
        "\n",
        "    n_iters_dcd = 4 * len(G2)\n",
        "    index_list_dcd = torch.randperm(n_iters_dcd)\n",
        "\n",
        "    mini_batch_size_g_h = 20 #data only contains G2 and G4 ,so decrease mini_batch\n",
        "\n",
        "    mini_batch_size_dcd= 40 #data contains G1,G2,G3,G4 so use 40 as mini_batch\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    X1 = []\n",
        "    X2 = []\n",
        "    ground_truths_y1 = []\n",
        "    ground_truths_y2 = []\n",
        "    dcd_labels=[]\n",
        "\n",
        "\n",
        "    for index in range(n_iters):\n",
        "\n",
        "\n",
        "        ground_truth=index_list[index]//len(G2)\n",
        "        x1, x2 = groups_2[ground_truth][index_list[index] - len(G2) * ground_truth]\n",
        "        y1, y2 = groups_y_2[ground_truth][index_list[index] - len(G2) * ground_truth]\n",
        "        # y1=torch.LongTensor([y1.item()])\n",
        "        # y2=torch.LongTensor([y2.item()])\n",
        "        dcd_label=0 if ground_truth==0 else 2\n",
        "        X1.append(x1)\n",
        "        X2.append(x2)\n",
        "        ground_truths_y1.append(y1)\n",
        "        ground_truths_y2.append(y2)\n",
        "        dcd_labels.append(dcd_label)\n",
        "\n",
        "        if (index+1)%mini_batch_size_g_h==0:\n",
        "\n",
        "            X1=torch.stack(X1)\n",
        "            X2=torch.stack(X2)\n",
        "            ground_truths_y1=torch.LongTensor(ground_truths_y1)\n",
        "            ground_truths_y2 = torch.LongTensor(ground_truths_y2)\n",
        "            dcd_labels=torch.LongTensor(dcd_labels)\n",
        "            X1=X1.to(device)\n",
        "            X2=X2.to(device)\n",
        "            ground_truths_y1=ground_truths_y1.to(device)\n",
        "            ground_truths_y2 = ground_truths_y2.to(device)\n",
        "            dcd_labels=dcd_labels.to(device)\n",
        "\n",
        "            optimizer_g_h.zero_grad()\n",
        "\n",
        "            encoder_X1=encoder(X1)\n",
        "            encoder_X2=encoder(X2)\n",
        "\n",
        "            X_cat=torch.cat([encoder_X1,encoder_X2],1)\n",
        "            y_pred_X1=classifier(encoder_X1)\n",
        "            y_pred_X2=classifier(encoder_X2)\n",
        "            y_pred_dcd=discriminator(X_cat)\n",
        "\n",
        "            loss_X1=loss_fn(y_pred_X1,ground_truths_y1)\n",
        "            loss_X2=loss_fn(y_pred_X2,ground_truths_y2)\n",
        "            loss_dcd=loss_fn(y_pred_dcd,dcd_labels)\n",
        "\n",
        "            loss_sum = loss_X1 + loss_X2 + 0.2 * loss_dcd\n",
        "\n",
        "            loss_sum.backward()\n",
        "            optimizer_g_h.step()\n",
        "\n",
        "            X1 = []\n",
        "            X2 = []\n",
        "            ground_truths_y1 = []\n",
        "            ground_truths_y2 = []\n",
        "            dcd_labels = []\n",
        "\n",
        "\n",
        "    #----training dcd ,g and h frozen\n",
        "    X1 = []\n",
        "    X2 = []\n",
        "    ground_truths = []\n",
        "    for index in range(n_iters_dcd):\n",
        "\n",
        "        ground_truth=index_list_dcd[index]//len(groups[1])\n",
        "\n",
        "        x1, x2 = groups[ground_truth][index_list_dcd[index] - len(groups[1]) * ground_truth]\n",
        "        X1.append(x1)\n",
        "        X2.append(x2)\n",
        "        ground_truths.append(ground_truth)\n",
        "\n",
        "        if (index + 1) % mini_batch_size_dcd == 0:\n",
        "            X1 = torch.stack(X1)\n",
        "            X2 = torch.stack(X2)\n",
        "            ground_truths = torch.LongTensor(ground_truths)\n",
        "            X1 = X1.to(device)\n",
        "            X2 = X2.to(device)\n",
        "            ground_truths = ground_truths.to(device)\n",
        "\n",
        "            optimizer_d.zero_grad()\n",
        "            X_cat = torch.cat([encoder(X1), encoder(X2)], 1)\n",
        "            y_pred = discriminator(X_cat.detach())\n",
        "            loss = loss_fn(y_pred, ground_truths)\n",
        "            loss.backward()\n",
        "            optimizer_d.step()\n",
        "            # loss_mean.append(loss.item())\n",
        "            X1 = []\n",
        "            X2 = []\n",
        "            ground_truths = []\n",
        "\n",
        "    #testing\n",
        "    acc_cl = []\n",
        "    acc = 0\n",
        "    for data, labels in test_dataloader:\n",
        "        data = data.to(device)\n",
        "        labels = labels.to(device)\n",
        "        y_test_pred = classifier(encoder(data))\n",
        "        acc += (torch.max(y_test_pred, 1)[1] == labels).float().mean().item()\n",
        "        \n",
        "        cur_data =   torch.tensor([0]*10).cuda()\n",
        "        test_pred =  torch.tensor([0]*10).cuda()\n",
        "        acc_class =  torch.tensor([0]*10).cuda()\n",
        "\n",
        "        \n",
        "        print(\"hui\")\n",
        "        for num_label in range(10):\n",
        "          \n",
        "           \n",
        "          cur_data[num_label] = torch.cat([data_.unsqueeze(1) for data_, labels_ in zip(data, labels) if labels_ == num_label])\n",
        "          #label_class[num_label] = torch.cat([labels_ for data_, labels_ in zip(data, labels) if labels_ == num_label])\n",
        "          test_pred[num_label] = classifier(encoder(cur_data[num_label]))\n",
        "\n",
        "          acc_class[num_label] +=  (torch.max(test_pred[num_label], 1)[1] == 0).float().mean().item()\n",
        "       \n",
        "\n",
        "    accuracy = round(acc / float(len(test_dataloader)), 3)\n",
        "    \n",
        "    acc_class_total = [round(element/ float(len(test_loader)),3) for element in acc_class]\n",
        "    acc_list.append(accuracy)\n",
        "    acc_cl.extend(acc_class_total)\n",
        "    \n",
        "\n",
        "    print(\"step3----Epoch %d/%d  accuracy: %.3f \" % (epoch + 1,  n_epochs_3, accuracy))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using downloaded and verified file: ./data/test_32x32.mat\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}